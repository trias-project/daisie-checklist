---
title: "Darwin Core mapping script for Description Extension"
subtitle: "For: Inventory of alien species in Europe (DAISIE)"
author:
- Lien Reyserhove
- David Roy
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

This file describes the steps required to map the data to [Darwin Core Description](https://tools.gbif.org/dwca-validator/extension.do?id=gbif:Description)

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r}
library(tidyverse)      # To do data science
library(magrittr)       # To use %<>% pipes
library(janitor)        # To clean input data
library(readxl)         # To read Excel files
library(rgbif)          # To use GBIF services
```

# Read data

1. Define data types

```{r}
col_types <- cols(.default = col_character())
```

2. Read habitat data (raw data)

```{r}
habitat <- read_delim(
  file = "../data/raw/input_habitat.csv", 
  delim = ",",
  col_types = col_types)
```

3. Read native range (raw data)

```{r}
native_range <- read_delim(
  file = "../data/raw/input_native_range.csv", 
  delim = ",",
  col_types = col_types)
```

4. Read `ecofunctional_group` (interim)

```{r}
ecofunctional_group <- read_delim(
  file = "../data/interim/ecofunctional_group.csv", 
  delim = ",",
  col_types = col_types)
```

5. Read `pathways` (raw)

```{r}
pathways <- read_delim(
  file = "../data/raw/input_pathways.csv", 
  delim = ",",
  col_types = col_types)
```

6. Read vector (raw)

```{r}
vectors  <- read_delim(
  file = "../data/raw/input_vectors.csv", 
  delim = ",", 
  col_types = col_types)
```

7. Read donor area (raw)

```{r}
donor_area <- read_delim(
  file = "../data/raw/input_donor_area.csv", 
  delim = ",",
  col_types = col_types)
```

8. Read impact (raw)

```{r}
impact <- read_delim(
  file = "../data/raw/input_impact.csv", 
  delim = ",",
  col_types = col_types)
```

10. Read current distribution (interim)

```{r}
current_distribution <- read_delim(
  file = "../data/interim/current_distribution.csv", 
  delim = ",",
  col_types = col_types)
```

11. Read population status (interim)

```{r}
population_status <- read_delim(
  file = "../data/interim/population_status.csv", 
  delim = ",",
  col_types = col_types)
```

12. Read region of first record (interim)

```{r}
region_of_first_record <- read_delim(
  file = "../data/interim/region_of_first_record.csv", 
  delim = ",",
  col_types = col_types)
```

13. Read `sp_in_region_with_location` (interim)

```{r}
sp_in_region_with_location <- read_delim(
  file = "../data/interim/sp_in_region_with_location.csv", 
  delim = ",",
  col_types = col_types)
```

14. Read `interim_literature_references` (interim)

```{r}
literature_references <- read_delim(
  file = "../data/interim/interim_literature_references.csv", 
  delim = ",",
  col_types = col_types)
```

15. Read `distribution_sources` (interim)

```{r}
distribution_sources <- read_delim(
  file = "../data/interim/distribution_sources.csv", 
  delim = ",",
  col_types = col_types)
```

15. Read `remove_taxa` (interim)

```{r}
remove_taxa <- read_delim(
  file = "../data/interim/remove_taxa.csv", 
  delim = ",",
  col_types = col_types)
```

# Create transformation functions

The description extension will be a combination of the following descriptors:
- habitat
- native range
- ecofunctional group

Each descriptor is imported as a separate dataset. We need to imply the same transformation steps to each dataset:

1. Remove all empty values (if applicable)
2. Keep distinct vaules only (if applicable)
3. Map `description`
4. Map `type`
5. Select relevant columns

As these steps are repeated for each of the description datasets, we write a function here.

```{r}
map_to_description <- function(data_frame, column_name, descriptor){
    data_frame %>% 
    
    # Remove empty values
    filter(
      (!!as.symbol(column_name)) != "" | 
        !is.na(!!as.symbol(column_name))) %>% 

    # keep distinct values only
    distinct(idspecies, (!!as.symbol(column_name)), .keep_all = TRUE) %>% 
    
    # Map description
    mutate(description = (!!as.symbol(column_name))) %>% 

    # Map type:
    mutate(type = descriptor) %>% 
  
    # Keep only `idspecies`, `description` and `type`:
    select(idspecies, description, type, sourceid)
} 
```

# Habitat

Generate `eunis_habitat`

```{r}
habitat %<>% mutate(eunis_habitat = case_when(
  !is.na(habitat) ~ paste(ideunis, "level", level, "-", habitat),
  TRUE ~ ideunis)
)
```

Apply transformation function:

```{r}
habitat <- 
  map_to_description(
    data_frame = habitat, 
    column_name = "eunis_habitat", 
    descriptor = "eunis habitat")
```

# Native range

```{r}
native_range <- 
  map_to_description(
    data_frame = native_range, 
    column_name = "region", 
    descriptor = "native range"
    )
```

# Ecofunctional group

```{r}
ecofunctional_group <- 
  map_to_description(
    data_frame = ecofunctional_group,
    column_name = "ecofunct_group",
    descriptor = "ecofunctional group"
    )
```

# Descriptors extention mapping

1. Combine `habitat`, `native_range` and `ecofunctional_group`

```{r}
description <- bind_rows(habitat, native_range, ecofunctional_group)
```

2. Link with `sourceid` from `literature_references`

```{r}
description %<>% 
  left_join(
    select(literature_references, sourceid, source),
    by = "sourceid")
```

3. Keep column names for description extension only and rename

```{r}
description <- 
  description %>% 
    select(idspecies, description, type, source) %>% 
    rename("taxonID" = "idspecies")
```

4. Scan for dupliated taxa (see [this issue](https://github.com/trias-project/daisie-checklist/issues/23)):

```{r}
taxonID_to_replace <- 
  description %>% 
    filter(taxonID %in% remove_taxa$idspecies) %>% 
    select(taxonID) %>% 
    unique()
taxonID_to_replace
```

5. Show replacement values:

```{r}
remove_taxa %>% 
  filter(idspecies %in% taxonID_to_replace$taxonID) %>% 
  select(idspecies, replacement_idspecies)
```

6. Replace these values with the correct taxonID

```{r}
description %<>% 
  mutate(taxonID = 
           recode(taxonID,
                 "52845" = "52831",
                 "900966" = "900975",
                 "900977" = "52847",
                 "900984" = "52858",
                 "900995" = "52877",
                 "900997" = "52878",
                 "901002" = "52889")
)
```

7. Sort on `taxonid`

```{r}
description %<>% arrange(taxonID)
```

8. Preview data:

```{r}
head(description, n=10)
```

5. Export as .csv

```{r}
write_csv(description, 
          here::here("data","processed","description.csv"), 
          na = "")
```

