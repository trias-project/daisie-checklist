---
title: "Darwin Core mapping"
subtitle: "For: Inventory of alien species in Europe (DAISIE)"
author:
- Lien Reyserhove
- Peter Desmet
- David Roy
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r}
library(tidyverse)      # To do data science
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(janitor)        # To clean input data
library(readxl)         # To read Excel files
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
library(lubridate)
```

# Read source data

```{r}
taxon <- read.csv("../data/raw/input_taxon.csv") 
vernacular_names <- read.csv("../data/raw/input_vernacular_names.csv")
distribution <- read.csv("../data/raw/input_distribution.csv", na.strings = "")
literature_references <- read.csv("../data/raw/input_literature_references.csv", na.strings = "")

# FOr the description extension:
pathways <- read.csv("../data/raw/input_pathways.csv")
vectors  <- read.csv("../data/raw/input_vectors.csv")
```

# Clean source data

```{r}
taxon <- taxon %>% clean_names()
vernacular_names <- vernacular_names %>% clean_names()
distribution <- distribution %>% clean_names()
literature_references <- literature_references %>% clean_names()
pathways <- pathways %>% clean_names()
vectors <- vectors %>% clean_names()
```


# Pre-processing

Extract information form `litarture_references` for sources or bibliographicCItation in the checklist:

```{r}
shortref <- literature_references %>% select(so_sourceid, so_shortref)
```

Inspect shortref values:

```{r}
shortref %>% 
  group_by(so_shortref) %>% 
  summarize(records = n())
```

# Taxon core

Preview data:

```{r}
taxon %>% head(n = 5)
```


## Term mapping

Map the data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml).

Start with record-level terms which contain metadata about the dataset (which is generally the same for all records).

### language

```{r}
taxon %<>% mutate(dwc_language = "en") 
```

### license

```{r}
taxon %<>% mutate(dwc_license = "http://creativecommons.org/licenses/by/4.0/legalcode") 
```

### rightsHolder

```{r}
taxon %<>% mutate(dwc_rightsHolder = "Centre for Ecology and Hydrology")
```

### reference

Inspect field `sourceID`:

```{r}
taxon %>% 
  group_by(sp_sourceid) %>% 
  summarise(records = n())
```

Add sources to taxon core:

```{r}
taxon %<>% left_join(
  select(literature_references, so_sourceid, so_shortref, so_longref),
  by = c("sp_sourceid" = "so_sourceid"))
```

Inspect longref:

```{r}
taxon %>% distinct(so_longref)
```

### datasetID

```{r}
taxon %<>% mutate(dwc_datasetID = "") 
```

### institutionCode

```{r}
taxon %<>% mutate(dwc_institutionCode = "CEH") 
```

### datasetName

```{r}
taxon %<>% mutate(dwc_datasetName = "Inventory of alien species in Europe (DAISIE)") 
```

The following terms contain information about the taxon:

### taxonID

```{r}
taxon %<>% mutate(dwc_taxonID = idspecies)
```

### scientificName

The information in `scientificName` is contained in several fields: `sp_genus`, `sp_species`, `sp_authority`, `sp_subtaxon` and `sp_subtaxon_authority`. We paste this information together to generate the field `dwc_scientificName`:

```{r}
taxon %<>% mutate(dwc_scientificName = paste(sp_genus, sp_species, sp_authority, sp_subtaxon, sp_subtaxon_authority, sep = " "))
```

Use the [GBIF nameparser](https://www.gbif.org/tools/name-parser) to retrieve nomenclatural information for the scientific names in the checklist:

```{r}
parsed_names <- taxon %>%
  distinct(dwc_scientificName) %>%
  pull() %>% # Create vector from dataframe
  parsenames() # An rgbif function
```

Show scientific names with nomenclatural issues, i.e. not of `type = SCIENTIFIC` or that could not be fully parsed. Note: these are not necessarily incorrect.

```{r}
nomenclatural_issues <- parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

Amount of scientific names with nomenclatural issues:

```{r}
nrow(nomenclatural_issues)
```

Inspect how many taxa are categorized under the different types:

```{r}
nomenclatural_issues %>% 
  group_by(type) %>% 
  summarize(records = n())
```

Some taxa need special inspection, especially the doubtful ones (probably due to UTF-8 issues)

### kingdom

### phylum

```{r}
taxon %<>% mutate(dwc_phylum = sp_phylum)
```

### class

```{r}
taxon %<>% mutate(dwc_class = sp_class) 
```

### order

```{r}
taxon %<>% mutate(dwc_order = sp_ordo) 
```

### family

```{r}
taxon %<>% mutate(dwc_family = sp_family) 
```

### genus

```{r}
taxon %<>% mutate(dwc_genus = sp_genus) 
```

### specificEpithet

```{r}
taxon %<>% mutate(dwc_specificEpithet = sp_species) 
```

### infraspecificEpithet

```{r}
taxon %<>% mutate(dwc_infraspecificEpithet = sp_subtaxon) 
```

### taxonRank

Information for `taxonRank` is provided in the field `subtaxon_rank`. However, this is only for the subtaxon level. The information is also provided by the GBIF nameparser function. We extract this information from the `parsed_names` and add it to `taxon`:

```{r}
taxon %<>% left_join(
  select(parsed_names, scientificname, rankmarker),
  by = c("dwc_scientificName" = "scientificname"))
```

Inspect `rankmarker` values and compare with `subtaxon_rank` information:

```{r}
taxon %>% 
  group_by(rankmarker, sp_subtaxon_rank) %>% 
  summarize(records = n()) %>% 
  arrange(desc(records)) %>% 
  kable()
```

### scientificNameAuthorship

### taxonRemarks

This field will include the information on ecofunctional groups (contained in `eg_ecofunct_group`)

```{r}
taxon %<>% mutate(dwc_taxonRemarks = paste("Ecofunctional_group", "=", eg_ecofunct_group, sep = " ")) 
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
taxon %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(taxon) <- str_replace(colnames(taxon), "dwc_", "")
```

Preview data:

```{r}
taxon %>% head()
```

Save to CSV:

```{r}
write_csv(taxon, here("data", "processed", "taxon.csv"), na = "")
```

# Vernacular names extension

Preview data:

```{r}
vernacular_names %>% head(n = 5)
```

## Tidy data

Clean data somewhat:

```{r}
vernacular_names <- 
  vernacular_names %>% 
    remove_empty("rows") %>% 
    clean_names()
  
```

## Term mapping

### taxonID

```{r}
vernacular_names %<>% mutate(dwc_taxonID = idspecies) 
```

### vernacularName

```{r}
vernacular_names %<>% mutate(dwc_vernacularName = cn_name) 
```

### source

```{r}

```

### language

Display all unique language information:

```{r}
vernacular_names %>% 
  group_by(cn_language) %>% 
  summarize(records = n())
```

Map language information to [ISO 639-1 Language Codes](https://tools.gbif.org/dwca-validator/vocabulary.do?id=http://iso.org/639-1)

```{r}
vernacular_names %<>% mutate(dwc_language = recode(cn_language,
  "Belorussian" = "be",
  "Czech" = "cs",
  "Danish" = "da",
  "Dutch" = "nl",
  "English" = "en",
  "Estonian" = "et",
  "Faeroese" = "fo",
  "Finnish" = "fi",
  "French" = "fr",
  "German" = "de",
  "Greek" = "el",
  "Hebrew (western characters)" = "he",
  "Hebrew (Hebrew characters)" = "he",
  "Hungarian" = "hu",
  "Icelandic" = "is",
  "Italian" = "it",
  "Latvian" = "lv",
  "Lithuanian" = "lt",
  "Maltese" = "mt",
  "Norwegian" = "no",
  "Polish" = "pl",
  "Portuguese" = "pt",
  "Romanian" = "ro",
  "Spanish" = "es",
  "Swedish" = "sv",
  "Turkish" = "tr"
))
```

Show mapping:

```{r}
vernacular_names %>% 
  group_by(cn_language, dwc_language) %>% 
  summarize(records = n())
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
vernacular_names %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(vernacular_names) <- str_replace(colnames(vernacular_names), "dwc_", "")
```

Preview data:

```{r}
vernacular_names %>% head()
```

Save to CSV:

```{r}
write_csv(vernacular_names, here("data", "processed", "vernacular_names.csv"), na = "")
```

# Distribution extension

## Term mapping

### taxonID

```{r}
distribution %<>% mutate(dwc_taxonID = idspecies) 
```

### locationID


In this field, we integrate information contained in `re_system_country`, `re_code_region`. When coastal information is provided, we combine this infomation with `re_system_coast` and `re_code_coast`.

```{r}
distribution %<>% mutate(dwc_locationID = case_when(
  is.na(re_region_coast) ~ paste(re_system_country, re_code_region, sep = ":"),
  TRUE ~ paste(
    paste(re_system_country, re_code_region, sep = ":"),
    paste(re_system_coast, re_code_coast, sep = ":"),
    sep = " - ")
))
```

### locality

In this field, we integrate all verbatim information contained in `re_region_country` and `re_region_coast` 
The format will be:

> country - coast

```{r}
distribution %<>% mutate(dwc_locality = case_when(
  is.na(re_region_coast) ~ paste(re_region_country),
  !is.na(re_region_coast) ~ paste(re_region_country, re_region_coast, sep = " - ")))
```

Save this information in a separate vector, as this is needed for the mapping of the descirption extension.

```{r}
species_localities <- distribution %>% 
  select(idspecies, id_sp_region, dwc_locationID)
```

### countryCode

```{r}
distribution %<>% mutate(countryCode = recode(re_region_country, 
"Albania"	                = "AL",
"Algeria"	                = "DZ",
"Andorra"	                = "AD",
"Austria"	                = "AT",
"Azores"                    = "PT",
"Baleares"	              = "ES",
"Belarus"	                = "BY",
"Belgium"	                = "BE",
"Bosnia-Herzegovina"	    = "BA",
"Bulgaria"	              = "BG",
"Canary Is."	            = "ES",
"Channel Is."	            = "UK",
"Corse (Corsica)"	        = "FR",
"Croatia"	                = "HR",
"Cyprus"	                = "CY",
"Czech Republic"	        = "CZ",
"Denmark"	                = "DK",
"Egypt"                 	= "EG",
"England"	                = "UK",
"Estonia"                 = "ES",
"Europe"	                = "",
"European part of Russia"	= "RU",
"Faroyar (Faroes)"	      = "FO",
"Finland"	                = "FI",
"France"	                = "FRR",
"Germany"	                = "DE",
"Gilbraltar"	            = "GI",
"Great Britain"	          = "UK",
"Greece"	                = "GRC-OO",
"Greece (East Aegean)"	  = "GR",
"Greece (Ionian Islands)" = "GR",
"Greece (North Aegean)"   = "GR",
"Greece (South Aegean)"   = "GR",
"Greenland"	              = "GL",
"Hungary"	                = "HU",
"Iceland"	                = "IS",
"Ireland"	                = "IE",
"Israel"	                = "IL",
"Italy"	                  = "IT",
"Kriti (Crete)"	          = "GR",
"Latvia"	                = "LV",
"Lebanon"	                = "LB",
"Libya"	                  = "LY",
"Liechtenstein"	          = "LI",
"Lithuania"	              = "LT",
"Luxembourg"	            = "LU",
"Macedonia"	              = "MK",
"Madeira"	                = "PT",
"Malta"	                  = "MT",
"Moldova"	                = "MD",
"Monaco"	                = "MC",
"Montenegro"	            = "YU",
"Morocco"	                = "MA",
"Netherlands"	            = "NL",
"Northern Ireland"	      = "UK",
"Norway"	                = "NO",
"Poland"	                = "PL",
"Portugal"	              = "PT",
"Romania"	                = "RO",
"Russian Far East"	      = "31",
"San Marino"	            = "SM",
"Sardegna (Sardinia)"	    = "IT",
"Scotland"	              = "UK",
"Serbia"	                = "YU",
"Sicilia"	                = "IT",
"Sicilia (Sicily)"	      = "IT",
"Slovakia"	              = "SK",
"Slovenia"	              = "SI",
"Spain"	                  = "ES",
"Svalbard"	              = "SJ",
"Sweden"	                = "SE",
"Switzerland"	            = "CH",
"Syria"	                  = "SY",
"Tunisia"	                = "TN",
"Turkey (in Europe)"	    = "TR",
"Ukraine"	                = "UA",
"United Kingdom"	        = "UK",
"Wales"	                  = "UK",
"Yugoslavia"	            = ""
))
```

### occurrenceStatus

```{r}
distribution %>% 
  group_by(ab_abundance, ps_population_status) %>% 
  summarize(records = n())
```

```{r}
distribution %<>% mutate(occurrenceStatus = case_when(
  ab_abundance == "Absent or extinct" & ps_population_status !="Extinct"     ~ "absent",
  ab_abundance == "Absent or extinct" & is.na(ps_population_status)          ~ "absent",
  (ps_population_status != "Extinct" | is.na(ps_population_status)) & ab_abundance == "Abundant"       ~ "common",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & ab_abundance == "Common"        ~ "common",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & ab_abundance == "Local"         ~ "present",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & ab_abundance == "Rare"          ~ "rare",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & ab_abundance == "Single record" ~ "present",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & ab_abundance == "Sporadic"      ~ "irregular",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & ab_abundance == "Unknown"       ~ "doubtful",
  (ps_population_status != "Extinct" | is.na(ps_population_status))  & is.na(ab_abundance)             ~ "",
  ps_population_status == "Extinct"                                    ~ "extinct"))
```

```{r}
distribution %>% 
  group_by(ab_abundance, ps_population_status, occurrenceStatus) %>% 
  summarize(records = n())
```

### establishmentMeans

### eventDate

Inspect content of `sir_start_year`, which contains the information for `eventDate`:

```{r}
distribution %>% 
  mutate(sir_start_year = as.character(sir_start_year)) %>%
  group_by(sir_start_year) %>% 
  summarize(records = n()) %>%
  arrange(desc(records))
```

Besides a lot of `NA` values, we have many `YYYY` formatted years (good to go) and a smaller group of _others_:

- NA cases:
  * Unknown -> NA
  * unknown -> NA
  * . -> NA
  * ? -> NA
  * since long -> NA
- negative years: also to NA
  * -5300, -2200, -750 -> NA
- before/after cases, question marks,... remove the </>/? signs
  * <1925   -> 1925, i.e. year itself
  * year with question mark, e;g. 1921?, 1930 ? -> year itself is best guess, so extract year
  * 1999\n -> clean to 1999  
- full dates: 10.06.1995., 01/04/1993, 15/10/2005,...  
- multiple years:
  * range of years: 1889-1892  -> take first year
  * options: '2000, 2001'; 1992 or 2010, 2000 OR 2004 -> take first year occurrence
- specials: 20. century, 1957*; 2008**, , 2004, earlier unconformed records, March,1993, 90`s
  * try to extract a 4-digit year (or use Damianos improvd funtionality)

The remaining will probably require some claenup manually. 

Get an overview of the amount of records with just a `YYYY` year format:

```{r}
distribution %>%
  select(sir_start_year) %>%
  filter(str_detect(sir_start_year, "^[0-9]{4}$")) %>% nrow()
```

We also have an amount of negative years to take into account. Let's just consider these with 3 or 4 digits:

```{r}
distribution %>%
  select(sir_start_year) %>%
  filter(str_detect(sir_start_year, "^(-[0-9]{4}|-[0-9]{3})")) %>% nrow()
```

Let's clean the start years information step by step:

1. Everything that is NA or should be NA, make it NA:

```{r}
distribution %<>% 
  mutate(sir_start_year = as.character(sir_start_year)) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "Unknown", NA)) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "unknown", NA)) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == ".", NA)) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "?", NA)) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "since long", NA)) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "Since long", NA))

```

2. For all negative values, make it NA:

```{r}
distribution %<>% 
  mutate(sir_start_year = 
           if_else(str_detect(sir_start_year, "^-[0-9]*"),
                   NA_character_, sir_start_year))
```

3. When using a `<` or `>` sign, with a `?` or `\n` added, just take the year:

```{r}
distribution %<>% 
  mutate(sir_start_year = str_replace(sir_start_year, "<|>|\\?", ""))
```

4. When a full date is available, parse it to ISO 8601 date format:

```{r}
full_date_indices <- str_detect(distribution$sir_start_year, 
                                "[0-9]*/[0-9]*/[0-9]*|[0-9]*\\.[0-9]*\\.[0-9]*") & !is.na(distribution$sir_start_year)
parsed_dates <- parse_date_time(distribution$sir_start_year[full_date_indices], orders = "dmy")
parsed_dates_char <- strftime(parsed_dates, "%d-%m-%Y")
distribution$sir_start_year[full_date_indices] <- parsed_dates_char
```

5. When textwise containing a single or multiple years, exrtact the first year in the text:

```{r}
# ignore already parsed dates for this replacement
not_date_indices <- !str_detect(distribution$sir_start_year, 
                               "[0-9]{2}-[0-9]{2}-[0-9]{4}") & !is.na(distribution$sir_start_year)
records_to_parse <- distribution$sir_start_year[not_date_indices]
extracted_years <- if_else(is.na(str_extract(records_to_parse, "[0-9]{4}")),
                           records_to_parse,
                           str_extract(records_to_parse, "[0-9]{4}"))
distribution$sir_start_year[not_date_indices] <- extracted_years
```

5. Replace some specials still present:

First have a look at the specials remaining, not being a integer year (1 or more digits [0-9]) or a formatted date format:

```{r}
distribution  %>%
  select(sir_start_year) %>%
  filter(!str_detect(sir_start_year, "^[0-9]+$|^[0-9]{2}-[0-9]{2}-[0-9]{4}$"))
```

and replace those values:

```{r}
distribution %<>% 
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "20. century", "1900")) %>%
  mutate(sir_start_year = replace(sir_start_year, sir_start_year == "90`s ", "1990"))
```


recheck cleanup action:

```{r}
distribution  %>%
  select(sir_start_year) %>%
  filter(!str_detect(sir_start_year, "^[0-9]+$|^[0-9]{2}-[0-9]{2}-[0-9]{4}$"))
```

Show content:

```{r}
distribution %>% 
  group_by(sir_start_year) %>% 
  summarize(records = n())
```

# Literature reference extension

## Tidy data

Clean data somewhat:

```{r}
literature_references <- 
  literature_references %>% 
    remove_empty("rows") %>% 
    clean_names()
```

## Term mapping

Inspect shortref

```{r}
literature_references %>% 
  group_by(so_shortref) %>% 
  summarize(records = n())
```

# Description extension

## Pathways

```{r}
pathways %>% 
  group_by(pathway) %>% 
  summarize(records = n())
```

Add regional information:

```{r}
pathways %<>% left_join(
  select(species_localities, id_sp_region, dwc_locationID),
  by = "id_sp_region") 
```

Map DwC terms:

### taxonID

```{r}
pathways %<>% mutate(dwc_taxonID = idspecies) 
```

### description

```{r}
pathways %<>% mutate(dwc_description = paste(dwc_locationID, pathway, sep = " - ")) 
```

### type

```{r}
pathways %<>% mutate(dwc_type = "pathway") 
```

### source

