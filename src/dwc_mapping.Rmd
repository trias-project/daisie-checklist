---
title: "Darwin Core mapping"
subtitle: "For: Inventory of alien species in Europe (DAISIE)"
author:
- Lien Reyserhove
- David Roy
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Load libraries:

```{r}
library(tidyverse)      # To do data science
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(janitor)        # To clean input data
library(readxl)         # To read Excel files
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
library(lubridate)      # To process dates and times
```

# Read source data

```{r}
col_types <- cols(
  .default = col_character())
```


```{r}
taxon <- read_csv("../data/raw/input_taxon.csv", col_types = col_types) 
vernacular_names <- read_csv("../data/raw/input_vernacular_names.csv", col_types = col_types)
distribution <- read_csv("../data/raw/input_distribution.csv", col_types = col_types)
literature_references <- read_csv("../data/raw/input_literature_references.csv", col_types = col_types)

# For the description extension:
pathways <- read_csv("../data/raw/input_pathways.csv", col_types = col_types)
vectors  <- read_csv("../data/raw/input_vectors.csv", col_types = col_types)
habitat <- read_csv("../data/raw/input_habitat.csv", col_types = col_types)
native_range <- read_csv("../data/raw/input_native_range.csv", col_types = col_types)
donor_area <- read_csv("../data/raw/input_donor_area.csv", col_types = col_types)
impact <- read_csv("../data/raw/input_impact.csv", col_types = col_types)
```

# Pre-processing

The file `literature_references` containes a detailed overview of all consulted sources used to compile DAISIE.

```{r}
literature_references %>% head(n=10)
```

Each source is composed of:
- a citation (`shortref`) and/or
- full references (`longref`) and/or
- `url`
Each source is identified by its `sourceid`

In many cases, sources are duplicated, i.e. the same source is attributed to a combination between:
- `id_sp_region` (an identifier for a species in a specific region) and/or
- `idspecies` (an identifier for a species) and/or
- `notes` (a specific trait of the species)
This is a consequence of the structure of `distribution` and will be discussed later.

Each input file (except `distribution`) includes the field `sourceid`. In the Darwin Core mapping process, we want to add the full reference to each record in the generated files, which implicates that we have to join the information in `literature_references` with the input file using `sourceid`. 
To accomplish this, we need to:

1. Compile the full reference from
- `shortref` and/or
- `longref` and/or
- `url`
2. Assign the full reference to `taxonRemarks` (in the taxon core) or `source` (for distribution, vernacular names and description extension) using the link with its ↨`sourceid`.
 
Inspection of `longref` values:

```{r}
literature_references %>% 
  group_by(longref) %>% 
  summarize(records = n()) %>%
  arrange(longref)
```

Cleaning the conent of this field is outside scope op this mapping). However, several `longref` values start with a number (e.g. `1`, `1, 28`). These are really not valuable for the dataset and can easily be removed:

```{r}
literature_references %<>% mutate(longref = str_replace(longref, "^[0-9]", NA_character_))
```

Check whether these values have been removed (should be `TRUE`)

```{r}
unique(literature_references %>%  str_detect("^[0-9]")) == FALSE
```

Inspection of content for `shortref`:

```{r}
literature_references %>% 
  group_by(shortref) %>% 
  summarize(records = n()) %>%
  arrange(shortref)
```

Cleaning of this fiels is outside of the scope of this mapping.

Inspection of `url` values:

```{r}
literature_references %>% 
  group_by(url) %>% 
  summarize(records = n()) %>%
  arrange(url)
```

The information contained in `url` is, in most cases, wrong: it contains scientific names rather than a real url. We remove these scientific names from this field:

```{r}
literature_references %<>%  mutate(url = if_else(str_detect(url, pattern = "^http"), url, NA_character_))
```

Check whether scientific names have been removed:

```{r}
literature_references %>% 
  group_by(url) %>% 
  summarize(records = n()) %>%
  arrange(url)
```

To compile the full references out of `shortref` and/or `longref` and/or `url`, we need to know which (and how many) combinations of these fields occur in `literature_references: 

```{r}
overview_references <- arrange(
  bind_cols(
        data.frame(matrix(c("","","",
                            "","", "x",
                            "", "x","",
                            "", "x", "x", 
                            "x","","",
                            "x","", "x",
                            "x","x","",
                            "x", "x", "x"),
                       nrow = 8, byrow = TRUE, 
                       dimnames = list(c(1:8), c("longref", "shortref", "url")))),
        data.frame(bind_rows(
          summarize(filter(literature_references, 
                           is.na(longref) & 
                           is.na(shortref) & 
                           is.na(url)),
                    records = n()),
          summarize(filter(literature_references,
                            is.na(longref) &
                            is.na(shortref) &
                           !is.na(url)),
                    records = n()),
          summarize(filter(literature_references, 
                           is.na(longref) &
                             !is.na(shortref) &
                             is.na(url)),
                    records = n()),
          summarize(filter(literature_references,
                           is.na(longref) &
                             !is.na(shortref) &
                             !is.na(url)),
                    records = n()),
          summarize(filter(literature_references,
                           !is.na(longref) &
                             is.na(shortref) &
                             is.na(url)),
                    records = n()),
          summarize(filter(literature_references,
                           !is.na(longref) &
                             is.na(shortref) &
                             !is.na(url)),
                    records = n()),
          summarize(filter(literature_references,
                           !is.na(longref) &
                             !is.na(shortref) &
                             is.na(url)),
                    records = n()),
          summarize(filter(literature_references,
                           !is.na(longref) &
                             !is.na(shortref) &
                             !is.na(url)),
                    records =n())))
        ),
  desc(records))
```

```{r}
overview_references
```

We here create a new field `source`, which is a combination of `longref` and/or `shortref` and/or `url`, depending on whether a value is provided:

```{r}
overview_references %>% mutate(source = case_when(
  longref == "x" & shortref == "x" & url == ""  ~ "longref",
  longref == "x" & shortref == ""  & url == ""  ~ "longref",
  longref == ""  & shortref == ""  & url == ""  ~ "",
  longref == ""  & shortref == "x" & url == ""  ~ "shortref",
  longref == "x" & shortref == "x" & url == "x" ~ "longref + url",
  longref == ""  & shortref == ""  & url == "x" ~ "url",
  longref == "x" & shortref == "" & url  == "x" ~ "longref + url",
  longref == ""  & shortref == "x" & url == "x" ~ "shortref + url"))
```

```{r}
rm(overview_references)
```

```{r}
literature_references %<>% mutate(source = case_when(
  !is.na(longref) & !is.na(shortref) & is.na(url) ~ paste(longref),
  !is.na(longref) & is.na(shortref)  & is.na(url) ~ paste(longref),
  is.na(longref)  & is.na(shortref)  & is.na(url) ~ "",
  is.na(longref)  & !is.na(shortref) & is.na(url) ~ paste(shortref),
  !is.na(longref) & is.na(shortref)  & !is.na(url) ~ paste(longref, paste0("(",url,")"), sep = ""),
  !is.na(longref) & !is.na(shortref) & !is.na(url) ~ paste(longref, paste0("(",url,")"), sep = ""),  
  is.na(longref)  & is.na(shortref)  & !is.na(url) ~ paste(url),  
  is.na(longref)  & !is.na(shortref) & !is.na(url) ~ paste(shortref, paste0("(",url,")"), sep = "")))  
```

By joining `source` in `literature_references` with `sourceid` in one of the input files (except `distribution`), we can add the full reference information to the records.

In the case of the distribution extension, a specific value for `source` can only be linked to a record using a combination between:
- `id_sp_region`
- `field_name`
We save this information in a separate dataframe `distribution_sources` here and use it later to generate the full reference for the distribution extension:

```{r}
distribution_sources <- 
  literature_references %>% 
    filter(!is.na(id_sp_region)) %>% 
    select(id_sp_region, field_name, sourceid, source)
```

Remove duplicated sources in `literature_references` (duplicated are only needed for the mapping of the distribution extension:

```{r}
literature_references %<>% distinct(sourceid, .keep_all = TRUE)
```

# Taxon core

Preview data:

```{r}
taxon %>% head(n = 5)
```

## Term mapping

Map the data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml).

Start with record-level terms which contain metadata about the dataset (which is generally the same for all records).

### language

```{r}
taxon %<>% mutate(dwc_language = "en") 
```

### license

```{r}
taxon %<>% mutate(dwc_license = "http://creativecommons.org/licenses/by/4.0/legalcode") 
```

### rightsHolder

```{r}
taxon %<>% mutate(dwc_rightsHolder = "Centre for Ecology and Hydrology")
```

### datasetID

```{r}
taxon %<>% mutate(dwc_datasetID = "") 
```

### institutionCode

```{r}
taxon %<>% mutate(dwc_institutionCode = "CEH") 
```

### datasetName

```{r}
taxon %<>% mutate(dwc_datasetName = "Inventory of alien species in Europe (DAISIE)") 
```

The following terms contain information about the taxon:

### taxonID

```{r}
taxon %<>% mutate(dwc_taxonID = idspecies)
```

### scientificName

The information in `scientificName` will be a compilation of several fields: `sp_genus`, `sp_species`, `sp_authority`, `sp_subtaxon` and `sp_subtaxon_authority`. We paste this information together to generate the field `dwc_scientificName`.

```{r}
taxon %<>% mutate(dwc_scientificName = paste(genus, species, authority, subtaxon, subtaxon_authority, sep = " "))
```

Remove all `NA`:

```{r}
taxon %<>% 
  mutate(dwc_scientificName = str_replace_all(dwc_scientificName, "NA", "")) %>% 
  mutate(dwc_scientificName = str_replace_all(dwc_scientificName, "(\\s){2,}", " ")) %>% 
  mutate(dwc_scientificName = trimws(dwc_scientificName))
```

Use the [GBIF nameparser](https://www.gbif.org/tools/name-parser) to retrieve nomenclatural information for the scientific names in the checklist:

```{r}
parsed_names <- taxon %>%
  distinct(dwc_scientificName) %>%
  pull() %>% # Create vector from dataframe
  parsenames() # An rgbif function
```

Show scientific names with nomenclatural issues, i.e. not of `type = SCIENTIFIC` or that could not be fully parsed. Note: these are not necessarily incorrect.

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE")) %>% 
  head(n=10)
```

Amount of scientific names with nomenclatural issues:

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE")) %>% 
  nrow()
```

Inspect how many taxa are categorized under the different types:

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE")) %>% 
  group_by(type) %>% 
  summarize(records = n())
```

Cleaning of the scientific names is outside the scope of this mapping process. However, we can perform some rough cleaning to eliminate the `INFORMAL` taxa, by removing `sp.:

```{r}
taxon %<>% mutate(dwc_scientificName = str_remove_all(dwc_scientificName,"sp."))
```

Re-parse after this cleaning step, to check whether the number of informal taxa decreased :

```{r}
parsed_names <- taxon %>%
  distinct(dwc_scientificName) %>%
  pull() %>% # Create vector from dataframe
  parsenames() # An rgbif function
```

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE")) %>% 
  group_by(type) %>% 
  summarize(records = n())
```

Some other taxa need special inspection, especially the doubtful ones (probably due to UTF-8 issues)

### kingdom

No kingdom information is provided. This is not an obligatory field but strongly recommended. It can easily be derived from information in `phylum`:

```{r}
taxon %>% 
  group_by(phylum) %>% 
  summarise(records = n())
```

However, 389 taxa have no phylum information provided. For these records, we try to derive phylum and kingdom information from `class`:

```{r}
taxon %>% 
  filter(is.na(phylum)) %>% 
  group_by(class) %>% 
  summarize(records = n())
```

Fist, we complete phylum information:

```{r}
taxon %<>% mutate(phylum_complete = case_when(
  class == "acari" |
    class == "chilopoda" |
    class == "crustacea" |
    class == "diplopoda" |
    class == "pauropoda" |
    class == "aranea" |
    class == "insecta" |
    class == "symphila" ~ "Arthropoda",
  class == "annelida" ~ "Annelida",
  class == "mollusca" ~ "Mollusca",
  class == "nematoda" ~ "Nematoda",
  class == "platyhelminthes" ~ "Platyhelminthes",
  TRUE ~ phylum))
```

(NB: some of these classes are not correct, e.g. `Nematoda` is a phylum, not a class. Cleaning this information is not within the scope of this mapping).

Summarize `phylum_complete`:

```{r}
taxon %>% 
  group_by(phylum_complete) %>% 
  summarise(records = n())
```

(NB: not all information is correct, e.g. `Bacteria` is a kingdom, not a phylum)

Based on this information, map `kingdom`:

```{r}
taxon %<>% mutate(dwc_kingdom = case_when(
phylum_complete == "Acanthocephala" |
  phylum_complete == "Annelida" |
  phylum_complete == "Arthropoda" |
  phylum_complete == "Bryozoa" |
  phylum_complete == "Chaetognatha" |
  phylum_complete == "Choradata" |
  phylum_complete == "Chordata" |
  phylum_complete == "Cnidaria" |
  phylum_complete == "Ctenophora" |
  phylum_complete == "Entoprocta" |
  phylum_complete == "Echinodermata" |
  phylum_complete == "Mollusca" |
  phylum_complete == "Myxozoa" |
  phylum_complete == "Nematoda" |
  phylum_complete == "Nemertea" |
  phylum_complete == "Phoronida" |
  phylum_complete == "Platyhelminthes" |
  phylum_complete == "Porifera" |
  phylum_complete == "Rotifera" |
  phylum_complete == "Sipunculida" ~ "Animalia",

phylum_complete == "Ascomycota" |
  phylum_complete == "Basidiomycota" |
  phylum_complete == "Chytridiomycota" |
  phylum_complete == "Fungi" |
  phylum_complete == "Oomycota" ~ "Fungi",

phylum_complete == "Bacteria" |
  phylum_complete == "Bacteroidetes" |
  phylum_complete == "Cyanobacteria" |
  phylum_complete == "Firmicutes" |
  phylum_complete == "Proteobacteria" ~ "Bacteria",

phylum_complete == "Anthocerotophyta" |
  phylum_complete == "Bryophyta" |
  phylum_complete == "Chlorophyta" |
  phylum_complete == "Cycadophyta" |
  phylum_complete == "Equisetophyta" |
  phylum_complete == "Ginkgoophyta" |
  phylum_complete == "Gnetophyta" |
  phylum_complete == "Magnoliophyta" |
  phylum_complete == "Marchantiophyta" |
  phylum_complete == "Monocotyledonae" |
  phylum_complete == "Pinophyta" |
  phylum_complete == "Polypodiophyta" |
  phylum_complete == "Rhodophyta" ~ "Plantae",

phylum_complete == "Cercozoa" |
  phylum_complete == "Ciliophora" |
  phylum_complete == "Cryptophyta" |
  phylum_complete == "Dinozoa" |
  phylum_complete == "Foraminifera" |
  phylum_complete == "Haptophyta" |
  phylum_complete == "Heterokontophyta" ~ "Chromista",

TRUE ~ ""
))
```

Summarize:

```{r}
taxon %>% 
  group_by(dwc_kingdom, phylum_complete) %>% 
  summarize(records = n())
```

### phylum

```{r}
taxon %<>% mutate(dwc_phylum = phylum)
```

### class

```{r}
taxon %<>% mutate(dwc_class = class) 
```

### order

```{r}
taxon %<>% mutate(dwc_order = ordo) 
```

### family

```{r}
taxon %<>% mutate(dwc_family = family) 
```

### genus

```{r}
taxon %<>% mutate(dwc_genus = genus) 
```

### specificEpithet

```{r}
taxon %<>% mutate(dwc_specificEpithet = species) 
```

### infraspecificEpithet

```{r}
taxon %<>% mutate(dwc_infraspecificEpithet = subtaxon) 
```

### taxonRank

Information for `taxonRank` is provided in the field `subtaxon_rank`, but is only for varieties, aggregates, hybrids, subspecies or forms. We can also obtain taxonRank information from `parsed_names` and add it to `taxon`:

```{r}
taxon %<>% left_join(
  select(parsed_names, scientificname, rankmarker),
  by = c("dwc_scientificName" = "scientificname"))
```

Inspect `rankmarker` values and compare with `subtaxon_rank` information:

```{r}
taxon %>% 
  group_by(rankmarker, subtaxon_rank) %>% 
  summarize(records = n()) %>% 
  arrange(desc(records)) 
```

We decided to use the information contained in `rankmarker` because GBIF rankmarker will provide cleaner information than `subtaxon_rank`, even if there might be some loss of information. However, rankmarker also contains `NA`. We inspect `dwc_scientificName` and `subtaxon_rank` for these values:

```{r}
taxon %>% 
  filter(is.na(rankmarker)) %>% 
  group_by(dwc_scientificName, subtaxon_rank) %>% 
  summarize(records = n()) %>% 
  arrange(subtaxon_rank)
```

Concrete actions to undertake:
- scientific names without `subtaxon_rank`:
    - `Acaena anserinifolia x inermis`: species
    - `Dahlia coccinea x pinnata`: species
    - `Geoplana (=Australoplana) sanguinea`: species
    - `Hyalomma Scupense "Delpy, 1946"`: species
    - `Rosa Hollandica'`: species
    - Rest: genera
- scientific names with `subtaxon_rank` = `agg.`: genus
- scientific names with `subtaxon_rank` = `hyb`: species
- scientific name = `Oidium Pseudoidium`: wrong scientific name, refers to genus `Oidium` or `Pseudoidium` 

```{r}
species_names <- c("Acaena anserinifolia x inermis", 
                   "Dahlia coccinea x pinnata",
                   "Geoplana (=Australoplana) sanguinea",
                   'Hyalomma Scupense "Delpy, 1946"',
                   "Rosa Hollandica'")
```


```{r}
taxon %<>% mutate(dwc_taxonRank = case_when(
  rankmarker == "sp."         ~ "species",
  rankmarker == "infrasp."    ~ "infraspecificname",
  rankmarker == "cv."         ~ "cultivar",
  rankmarker == "infrasubsp." ~ "infrasubspecificname",
  rankmarker == "var."        ~ "variety",
  rankmarker == "subvar."     ~ "subvariety",
  rankmarker == "subf."       ~ "subform",
  rankmarker == "subsp."      ~ "subspecies",
  rankmarker == "f."          ~ "form", 
  rankmarker ==  "morph"      ~ "morphovar",
  rankmarker == "pv."         ~ "pathovar",
  rankmarker == "subtrib."    ~ "subtribe",
  is.na(rankmarker) & is.na(subtaxon_rank) & !(dwc_scientificName %in% species_names) ~ "genus",
  is.na(rankmarker) & is.na(subtaxon_rank) & dwc_scientificName %in% species_names ~ "species",
  is.na(rankmarker) & subtaxon_rank == "agg." ~ "genus",
  is.na(rankmarker) & subtaxon_rank == "hyb." ~ "species",
  is.na(rankmarker) & subtaxon_rank == "subsp." ~ "subspecies",
  TRUE ~ rankmarker))
```

summarize mapping:

```{r}
taxon %>% 
  group_by(rankmarker, subtaxon_rank, dwc_taxonRank) %>% 
  summarize(records = n()) %>% 
  arrange(desc(records)) 
```

### scientificNameAuthorship

The `taxon` file now contains two fields refering to an authorship: `authority` and `subtaxon_authority`. When values for `subtaxon_authority` are provided, we use these values as `scientificNameAuthorship`. If only a value for `authority` is provided, we use this value.

```{r}
taxon %<>% mutate(dwc_scientificNameAuthorship = case_when(
  authority == "" & subtaxon_authority == "" ~ authority,
  authority == "" & subtaxon_authority != "" ~ subtaxon_authority,
  authority != "" & subtaxon_authority == "" ~ authority,
  authority != "" & subtaxon_authority != "" ~ subtaxon_authority))
```

### taxonRemarks

`taxon` contains a reference to sources (`sourceid`). These sources can not be classified a bibliographic citations. For this reason, we map these sources under `taxonRemarks`.

```{r}
taxon %<>% left_join(
  select(literature_references, sourceid, source),
  by = "sourceid")
```

## Post-processing

 `taxon` contains two more fields that have not been mapped yet
 - `ecofunct_group`
 - `taxon_group`
 We integrate this information in the description extension. 

Save information on ecofunctional groups (`ecofunct_group`):

```{r}
ecofunctional_group <- taxon %>% 
  select(idspecies, ecofunct_group, sourceid) %>% 
  distinct(idspecies, ecofunct_group, .keep_all = TRUE)
```

Save information about taxon group (`taxon_group`):

```{r}
taxon_group <- taxon %>% select(idspecies, taxon_group, sourceid) %>% 
  distinct(idspecies, taxon_group, .keep_all = TRUE)
```

Only keep the Darwin Core columns:

```{r}
taxon %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(taxon) <- str_replace(colnames(taxon), "dwc_", "")
```

Sort on taxonID

```{r}
taxon %<>% arrange(taxonID)
```

Preview data:

```{r}
taxon %>% head()
```

Save to CSV:

```{r}
write_csv(taxon, "../data/processed/taxon.csv", na = "")
```

# Vernacular names extension

```{r}
vernacular_names %>% head(n = 5)
```

## Term mapping

Map the data to [Vernacular Names](http://rs.gbif.org/extension/gbif/1.0/vernacularname.xml).

### taxonID

```{r}
vernacular_names %<>% mutate(dwc_taxonID = idspecies) 
```

### vernacularName

```{r}
vernacular_names %<>% mutate(dwc_vernacularName = name) 
```

### source

Join `vernacular_names` with `source` information in `literature_references`:

```{r}
vernacular_names %<>% left_join(
  select(literature_references, sourceid, source),
  by = "sourceid"
) 
```

### language

Display all unique language information:

```{r}
vernacular_names %>% 
  group_by(language) %>% 
  summarize(records = n())
```

Map language information to [ISO 639-1 Language Codes](https://tools.gbif.org/dwca-validator/vocabulary.do?id=http://iso.org/639-1)

```{r}
vernacular_names %<>% mutate(dwc_language = recode(language,
  "Belorussian" = "be",
  "Czech" = "cs",
  "Danish" = "da",
  "Dutch" = "nl",
  "English" = "en",
  "Estonian" = "et",
  "Faeroese" = "fo",
  "Finnish" = "fi",
  "French" = "fr",
  "German" = "de",
  "Greek" = "el",
  "Hebrew (western characters)" = "he",
  "Hebrew (Hebrew characters)" = "he",
  "Hungarian" = "hu",
  "Icelandic" = "is",
  "Italian" = "it",
  "Latvian" = "lv",
  "Lithuanian" = "lt",
  "Maltese" = "mt",
  "Norwegian" = "no",
  "Polish" = "pl",
  "Portuguese" = "pt",
  "Romanian" = "ro",
  "Spanish" = "es",
  "Swedish" = "sv",
  "Turkish" = "tr"
))
```

Show mapping:

```{r}
vernacular_names %>% 
  group_by(language, dwc_language) %>% 
  summarize(records = n())
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
vernacular_names %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(vernacular_names) <- str_replace(colnames(vernacular_names), "dwc_", "")
```

Preview data:

```{r}
vernacular_names %>% head()
```

Sort on `taxonID`:

```{r}
vernacular_names %<>% arrange(taxonID) 
```

Save to CSV:

```{r}
write_csv(vernacular_names, "../data/processed/vernacular_names.csv", na = "")
```

# Distribution extension

## Pre-processing

Inspect column names in `distribution`:

```{r}
distribution %>% colnames()
```

The following variables have no equivalent Darwin Core term in the distribution extension:
- `population_status`
- `current_distribution`
- `region_of_first_record`

. We save the information in a separate dataframes and map the information in the description extension:

```{r}
degree_of_establishment <- distribution %>% 
  select(idspecies, id_sp_region, population_status) %>% 
  distinct(id_sp_region, .keep_all = TRUE)
```

Keep all information on current_distribution:

```{r}
current_distribution <- distribution %>% 
  select(idspecies, id_sp_region, current_distribution) %>% 
  distinct(id_sp_region, .keep_all = TRUE)
```

Keep all information on first_observation:

```{r}
region_first_record <- distribution %>% 
  select(idspecies, id_sp_region, region_of_first_record) %>% 
  distinct(id_sp_region, .keep_all = TRUE)
```


Keep information on population_status:

species_status | population_status | establishmentMeans | degreeOfEstablishment
--- | ---
Alien | Established | introduced | established 
Alien | Extinct | introduced | extinct 
Alien | Not established | introduced | failed
Alien | Unknown or NA | introduced | 
Alien_invasive | Established | introduced | invasive
Alien_invasive | Extinct | introduced | extinct
Alien_invasive | Not established | | 
Alien_invasive | Unknown or NA | introduced | invasive
Casual | | Casual | vagrant |
Cryptogenic | Established | uncertain | established
Cryptogenic | Extinct | uncertain | extinct
Cryptogenic | NOt Established | uncertain | failed
Cryptogenic | Unknown or NA | uncertain | established |
Naturalized | NA | introduced | established
NA | Established | | established
NA | Extinct | | extinct
NA | Not established | failed
NA | NA/unknown | NA | NA

Map the data to [Species Distribution](http://rs.gbif.org/extension/gbif/1.0/distribution.xml).

## taxonID

```{r}
distribution %<>% mutate(dwc_taxonID = idspecies) 
```

## locationID

Information about locations is contained in six fields in total. This information is used to map `locationID` and `locality`. 

Two fields refer to verbatim location information (mapped to `locality`):
- `region_country`
- `region_coast`

Two fields refer to a location codes (mapped to `locationID`):
- `code_region`  (for location linked to coountries)
- `code_coast` (forl location linked to coastal areas)

These codes originate from different sources (mapped to `locationID`):
- `system_country`
- `system_coast` 


```{r}
distribution %>% 
  group_by(region_country, code_region, system_country, region_coast, code_coast, system_coast) %>% 
  summarize(records = n())
```

Note that coastal information is not always provided (`NA`). For these records, we will not integrate information into `locationID` and `locality` from coastal areas.

This is how we will map `locationID` and `locality`:

region_country | region_coast | locationID | locality
--- | --- | --- | ---
country | NA | system_country: code_region | region_country
country | coast | system_country: code_region|system_coast: code_coast | region_country|region_coast

Map `locationID`:

```{r}
distribution %<>% mutate(dwc_locationID = case_when(
  is.na(region_coast) ~ paste(system_country, code_region, sep = ": "),
  TRUE ~ paste(
              paste(system_country, code_region, sep = ":"),
              paste(system_coast, code_coast, sep = ":"),
              sep = "|")))
```

Map `locality`:

```{r}
distribution %<>% mutate(dwc_locality = case_when(
  is.na(region_coast)  ~ paste(region_country),
  !is.na(region_coast) ~ paste(region_country, region_coast, sep = "|")))
```

Some information in the description extension (e.g. for `impact on use` or `impact on ecolgy`) is a property of a taxon in a particular _region_ (identified by `id_sp_region`), rather than a property of a species as a whole. 
To emphasize that this description record is linked to a taxon in a particular region, we will add the `locationID` to the descriptor:

idspecies | sp_in_region | description | description_with_locationID
--- | --- | --- | ---
A | A_1 | impact_on_use_A1 |impact_on_use_A1 (locationID)
A | A_2 | impact_on_use_A2 | impact_on_use_A2 (locationID)

We here save the link between `id_sp_region` and `locationID`in a separate dataframe, to use it later in the mapping of the description extension:

```{r}
sp_in_region_locationID <- distribution %>% 
  select(idspecies, id_sp_region, dwc_locationID)
```

## countryCode

```{r}
distribution %<>% mutate(countryCode = recode(region_country, 
"Albania"	                = "AL",
"Algeria"	                = "DZ",
"Andorra"	                = "AD",
"Austria"	                = "AT",
"Azores"                  = "PT",
"Baleares"	              = "ES",
"Belarus"	                = "BY",
"Belgium"	                = "BE",
"Bosnia-Herzegovina"	    = "BA",
"Bulgaria"	              = "BG",
"Canary Is."	            = "ES",
"Channel Is."	            = "UK",
"Corse (Corsica)"	        = "FR",
"Croatia"	                = "HR",
"Cyprus"	                = "CY",
"Czech Republic"	        = "CZ",
"Denmark"	                = "DK",
"Egypt"                 	= "EG",
"England"	                = "UK",
"Estonia"                 = "ES",
"Europe"	                = "",
"European part of Russia"	= "RU",
"Faroyar (Faroes)"	      = "FO",
"Finland"	                = "FI",
"France"	                = "FRR",
"Germany"	                = "DE",
"Gilbraltar"	            = "GI",
"Great Britain"	          = "UK",
"Greece"	                = "GRC-OO",
"Greece (East Aegean)"	  = "GR",
"Greece (Ionian Islands)" = "GR",
"Greece (North Aegean)"   = "GR",
"Greece (South Aegean)"   = "GR",
"Greenland"	              = "GL",
"Hungary"	                = "HU",
"Iceland"	                = "IS",
"Ireland"	                = "IE",
"Israel"	                = "IL",
"Italy"	                  = "IT",
"Kriti (Crete)"	          = "GR",
"Latvia"	                = "LV",
"Lebanon"	                = "LB",
"Libya"	                  = "LY",
"Liechtenstein"	          = "LI",
"Lithuania"	              = "LT",
"Luxembourg"	            = "LU",
"Macedonia"	              = "MK",
"Madeira"	                = "PT",
"Malta"	                  = "MT",
"Moldova"	                = "MD",
"Monaco"	                = "MC",
"Montenegro"	            = "YU",
"Morocco"	                = "MA",
"Netherlands"	            = "NL",
"Northern Ireland"	      = "UK",
"Norway"	                = "NO",
"Poland"	                = "PL",
"Portugal"	              = "PT",
"Romania"	                = "RO",
"Russian Far East"	      = "31",
"San Marino"	            = "SM",
"Sardegna (Sardinia)"	    = "IT",
"Scotland"	              = "UK",
"Serbia"	                = "YU",
"Sicilia"	                = "IT",
"Sicilia (Sicily)"	      = "IT",
"Slovakia"	              = "SK",
"Slovenia"	              = "SI",
"Spain"	                  = "ES",
"Svalbard"	              = "SJ",
"Sweden"	                = "SE",
"Switzerland"	            = "CH",
"Syria"	                  = "SY",
"Tunisia"	                = "TN",
"Turkey (in Europe)"	    = "TR",
"Ukraine"	                = "UA",
"United Kingdom"	        = "UK",
"Wales"	                  = "UK",
"Yugoslavia"	            = ""
))
```

## occurrenceStatus

Information for `occurrenceStatus` is contained in two fields: `abundance` and `population_status`.
Inspect these values:

```{r}
distribution %>% 
  group_by(abundance, population_status) %>% 
  summarize(records = n())
```

In most cases , we can translate `abundance` to the GBIF [controlled vocabulary](http://rs.gbif.org/vocabulary/gbif/occurrence_status.xml) of `occurrenceStatus`:

abundance | occurrenceStatus 
--- | ---
common | common
abundant | common
rare | rare
local | present
single record | present
sporadic | irregular
unknown | doubtful

However, for 30 taxa, `population_status` contains the field `extinct`, which is valuable information for `occurrenceStatus`:

|population_status |abundance         | records|
|:-----------------|:-----------------|-------:|
|Extinct           |Absent or extinct |       9|
|Extinct           |Local             |       6|
|Extinct           |Rare              |      11|
|Extinct           |Single record     |       4|
|Extinct           |Unknown           |       8|

After discussing this through (see [this issue](https://github.com/trias-project/daisie-checklist/issues/4) on GitHub), we decided set `occurrencesStatus` as `extinct`, irrespective of the content of `abundance`.

```{r}
distribution %<>% mutate(dwc_occurrenceStatus = case_when(
  abundance == "Absent or extinct" & population_status !="Extinct"     ~ "absent",
  abundance == "Absent or extinct" & is.na(population_status)          ~ "absent",
  (population_status != "Extinct" | is.na(population_status)) & abundance == "Abundant"       ~ "common",
  (population_status != "Extinct" | is.na(population_status))  & abundance == "Common"        ~ "common",
  (population_status != "Extinct" | is.na(population_status))  & abundance == "Local"         ~ "present",
  (population_status != "Extinct" | is.na(population_status))  & abundance == "Rare"          ~ "rare",
  (population_status != "Extinct" | is.na(population_status))  & abundance == "Single record" ~ "present",
  (population_status != "Extinct" | is.na(population_status))  & abundance == "Sporadic"      ~ "irregular",
  (population_status != "Extinct" | is.na(population_status))  & abundance == "Unknown"       ~ "doubtful",
  (population_status != "Extinct" | is.na(population_status))  & is.na(abundance)             ~ "",
  population_status == "Extinct"                                    ~ "extinct"))
```

Show mapping:

```{r}
distribution %>% 
  group_by(abundance, population_status, dwc_occurrenceStatus) %>% 
  summarize(records = n())
```

## establishmentMeans

Information for `establishmentMeans` is contained in `species_status`:

```{r}
distribution %>% 
  group_by(species_status) %>% 
  summarize(records = n())
```

For mapping `soecies_status` to `establishmentMeans`, see [issue 15](https://github.com/trias-project/daisie-checklist/issues/15) on GitHub:

```{r}
distribution %<>% mutate(dwc_establishmentMeans = recode(species_status,
    "Alien" = "introduced",
    "Cryptogenic" = "uncertain",
    "<NA>" = "",
    "Naturalized" = "introduced",
    "casual" = "vagrant",
    "Alien_invasive" = "introduced")) 
```

## eventDate

Inspect content of `start_year`, which contains the information for `eventDate`:

```{r}
distribution %>% 
  mutate(start_year = as.character(start_year)) %>%
  group_by(start_year) %>% 
  summarize(records = n()) %>%
  arrange(desc(records))
```

Besides a lot of `NA` values, we have many `YYYY` formatted years (good to go) and a smaller group of _others_:

- NA cases:
  * Unknown -> NA
  * unknown -> NA
  * . -> NA
  * ? -> NA
  * since long -> NA
- negative years: also to NA
  * -5300, -2200, -750 -> NA
- before/after cases, question marks,... remove the </>/? signs
  * <1925   -> 1925, i.e. year itself
  * year with question mark, e;g. 1921?, 1930 ? -> year itself is best guess, so extract year
  * 1999\n -> clean to 1999  
- full dates: 10.06.1995., 01/04/1993, 15/10/2005,...  
- multiple years:
  * range of years: 1889-1892  -> take first year
  * options: '2000, 2001'; 1992 or 2010, 2000 OR 2004 -> take first year occurrence
- specials: 20. century, 1957*; 2008**, , 2004, earlier unconformed records, March,1993, 90`s
  * try to extract a 4-digit year (or use Damianos improvd funtionality)

The remaining will probably require some claenup manually. 

Get an overview of the amount of records with just a `YYYY` year format:

```{r}
distribution %>%
  select(start_year) %>%
  filter(str_detect(start_year, "^[0-9]{4}$")) %>% nrow()
```

We also have an amount of negative years to take into account. Let's just consider these with 3 or 4 digits:

```{r}
distribution %>%
  select(start_year) %>%
  filter(str_detect(start_year, "^(-[0-9]{4}|-[0-9]{3})")) %>% nrow()
```

Let's clean the start years information step by step:

1. Everything that is NA or should be NA, make it NA:

```{r}
distribution %<>% 
  mutate(start_year = as.character(start_year)) %>%
  mutate(start_year = replace(start_year, start_year == "Unknown", NA)) %>%
  mutate(start_year = replace(start_year, start_year == "unknown", NA)) %>%
  mutate(start_year = replace(start_year, start_year == ".", NA)) %>%
  mutate(start_year = replace(start_year, start_year == "?", NA)) %>%
  mutate(start_year = replace(start_year, start_year == "since long", NA)) %>%
  mutate(start_year = replace(start_year, start_year == "Since long", NA))

```

2. For all negative values, make it NA:

```{r}
distribution %<>% 
  mutate(start_year = 
           if_else(str_detect(start_year, "^-[0-9]*"),
                   NA_character_, start_year))
```

3. When using a `<` or `>` sign, with a `?` or `\n` added, just take the year:

```{r}
distribution %<>% 
  mutate(start_year = str_replace(start_year, "<|>|\\?", ""))
```

4. When a full date is available, parse it to ISO 8601 date format:

```{r}
full_date_indices <- str_detect(distribution$start_year, 
                                "[0-9]*/[0-9]*/[0-9]*|[0-9]*\\.[0-9]*\\.[0-9]*") & !is.na(distribution$start_year)
parsed_dates <- parse_date_time(distribution$start_year[full_date_indices], orders = "dmy")
parsed_dates_char <- strftime(parsed_dates, "%d-%m-%Y")
distribution$start_year[full_date_indices] <- parsed_dates_char
```

5. When textwise containing a single or multiple years, exrtact the first year in the text:

```{r}
# ignore already parsed dates for this replacement
not_date_indices <- !str_detect(distribution$start_year, 
                               "[0-9]{2}-[0-9]{2}-[0-9]{4}") & !is.na(distribution$start_year)
records_to_parse <- distribution$start_year[not_date_indices]
extracted_years <- if_else(is.na(str_extract(records_to_parse, "[0-9]{4}")),
                           records_to_parse,
                           str_extract(records_to_parse, "[0-9]{4}"))
distribution$start_year[not_date_indices] <- extracted_years
```

5. Replace some specials still present:

First have a look at the specials remaining, not being a integer year (1 or more digits [0-9]) or a formatted date format:

```{r}
distribution  %>%
  select(start_year) %>%
  filter(!str_detect(start_year, "^[0-9]+$|^[0-9]{2}-[0-9]{2}-[0-9]{4}$"))
```

and replace those values:

```{r}
distribution %<>% 
  mutate(start_year = replace(start_year, start_year == "20. century", "1900")) %>%
  mutate(start_year = replace(start_year, start_year == "90`s ", "1990"))
```

recheck cleanup action:

```{r}
distribution  %>%
  select(start_year) %>%
  filter(!str_detect(start_year, "^[0-9]+$|^[0-9]{2}-[0-9]{2}-[0-9]{4}$"))
```

Show content:

```{r}
distribution %>% 
  group_by(start_year) %>% 
  summarize(records = n())
```

Inspect content of `end_year`, which contains the information for `eventDate`:

```{r}
distribution %>% 
  mutate(end_year = as.character(end_year)) %>%
  group_by(end_year) %>% 
  summarize(records = n()) %>%
  arrange(desc(records))
```

Besides a lot of `NA` values, we have many `YYYY` formatted years (good to go) and a smaller group of _others_:

- NA cases:
  * unknown -> NA
  *   -> NA
  * ? -> NA
- negative years: also to NA
  * -2200, -750 -> NA
- before/after cases, question marks,... remove the </>/? signs
  * year with question mark, 2004? -> year itself is best guess, so extract year
- full dates: 15.06.2003.
- specials: 20. century, 1950's*
  try to extract a 4-digit year (or use Damianos improvd funtionality)

The remaining will probably require some claenup manually. 

Get an overview of the amount of records with just a `YYYY` year format:

```{r}
distribution %>%
  select(end_year) %>%
  filter(str_detect(end_year, "^[0-9]{4}$")) %>% nrow()
```

We also have an amount of negative years to take into account. Let's just consider these with 3 or 4 digits:

```{r}
distribution %>%
  select(end_year) %>%
  filter(str_detect(end_year, "^(-[0-9]{4}|-[0-9]{3})")) %>% nrow()
```

Let's clean the start years information step by step:

1. Everything that is NA or should be NA, make it NA:

```{r}
distribution %<>% 
  mutate(end_year = as.character(end_year)) %>%
  mutate(end_year = replace(end_year, end_year == " ", NA)) %>% 
  mutate(end_year = replace(end_year, end_year == "        ", NA)) %>% 
  mutate(end_year = replace(end_year, end_year == "unknown", NA)) %>%
  mutate(end_year = replace(end_year, end_year == "?", NA)) 
```

2. For all negative values, make it NA:

```{r}
distribution %<>% 
  mutate(end_year = 
           if_else(str_detect(end_year, "^-[0-9]*"),
                   NA_character_, end_year))
```

3. When using a `<` or `>` sign, with a `?` or `\n` added, just take the year:

```{r}
distribution %<>% 
  mutate(end_year = str_replace(end_year, "<|>|\\?", ""))
```

4. When a full date is available, parse it to ISO 8601 date format:

```{r}
full_date_indices <- str_detect(distribution$end_year, 
                                "[0-9]*/[0-9]*/[0-9]*|[0-9]*\\.[0-9]*\\.[0-9]*") & !is.na(distribution$end_year)
parsed_dates <- parse_date_time(distribution$end_year[full_date_indices], orders = "dmy")
parsed_dates_char <- strftime(parsed_dates, "%d-%m-%Y")
distribution$end_year[full_date_indices] <- parsed_dates_char
```

5. When textwise containing a single or multiple years, exrtact the first year in the text:

```{r}
# ignore already parsed dates for this replacement
not_date_indices <- !str_detect(distribution$end_year, 
                               "[0-9]{2}-[0-9]{2}-[0-9]{4}") & !is.na(distribution$end_year)
records_to_parse <- distribution$end_year[not_date_indices]
extracted_years <- if_else(is.na(str_extract(records_to_parse, "[0-9]{4}")),
                           records_to_parse,
                           str_extract(records_to_parse, "[0-9]{4}"))
distribution$end_year[not_date_indices] <- extracted_years
```

5. Replace some specials still present:

First have a look at the specials remaining, not being a integer year (1 or more digits [0-9]) or a formatted date format:

```{r}
distribution  %>%
  select(end_year) %>%
  filter(!str_detect(end_year, "^[0-9]+$|^[0-9]{2}-[0-9]{2}-[0-9]{4}$"))
```

and replace those values:

```{r}
distribution %<>% 
  mutate(end_year = replace(end_year, end_year == "19th century", "1800")) %>%
  mutate(end_year = replace(end_year, end_year == "1950's", "1950"))
```


recheck cleanup action:

```{r}
distribution  %>%
  select(end_year) %>%
  filter(!str_detect(end_year, "^[0-9]+$|^[0-9]{2}-[0-9]{2}-[0-9]{4}$"))
```

Show content:

```{r}
distribution %>% 
  group_by(end_year) %>% 
  summarize(records = n())
```

Inspect all combinations for `start_year` and `end_year`:

```{r}
distribution %>% group_by(start_year, end_year) %>% summarize(records = n())
```

Inspect which `end_year` falls before `start_year`:

```{r}
distribution %>% 
  mutate(end_year = as.numeric(end_year)) %>% 
  mutate(start_year = as.numeric(start_year)) %>% 
  filter(end_year < start_year) %>% 
  select(idspecies, end_year, start_year)
```

Create eventDate:

```{r}
distribution %<>% mutate(dwc_eventDate = case_when(
  is.na(start_year) & is.na(end_year) ~ "",
  is.na(start_year) & !is.na(end_year) ~ end_year,
  !is.na(start_year) & is.na(end_year) ~ start_year,
  !is.na(start_year) & !is.na(end_year) ~ paste(start_year, end_year, sep="/")
))
```

Generate occurrenceRemarks:

```{r}
distribution %<>% mutate(dwc_occurrenceRemarks = case_when(
  is.na(region_of_first_record) | region_of_first_record == "" ~ "",
  !is.na(region_of_first_record) ~ paste("region_of_first_record", region_of_first_record, sep = ": ")))
```

## source

In the distribution extension, there's no sourceID available


`source` information is extracted from `distribution_sources`. We link this information to `distribution` by using a combination between `id_sp_region` and `field_name`, with the content of `field_name` referring to the specific column names in `input_distribution`

Thus, we need to match this dataset

id_sp_region | field_name | source
--- | --- | ---
1 | field_A | source1
1 | field_B | source2 
2 | field_A | source3
2 | field_B | source4
3 | field_A | source5
3 | field_B | source6

with this dataset

id_sp_region | field_A | field_B
--- | --- | ---
1 | a | x 
2 | b | y
3 | c | z

For this, we need to transform `distribution_sources` from a long to a wide dataset: 

```{r}
distribution_sources %<>% spread(field_name, source)
```

clean column names in `distribution_sources`:

```{r}
distribution_sources %<>% clean_names() 
```

View the field names:

```{r}
distribution_sources %>% 
  select(-id_sp_region, -sourceid) %>% 
  colnames()
```

Some remarks:
- These field names do match with the field names in `distribution`,
- Some field names are linked to variables in `distribution`
  - `distribution`,
  - `general_references`,
  - `introduction dates`,
  - `introduction_history`
- Some field names are linked to variables to be included in `description`
  - `current_distrib`,
  - `current_distribution`,
  - `ecoimpact_id`,
  - `ecological impact`,
  - `first_observation`
  - `impact on uses`,
  - `status`
  - `useimpact_id`
- Some field_names are very similar, such as `current_distrib` and `current_distribution`. 

We here map source information for `distribution`. All sources are concatenated with ´|´ as a separator. We then remove all `NA` values:

```{r}
distribution_sources %<>% mutate(source = paste(
  distribution, 
  general_references, 
  introduction_dates, 
  introduction_history, 
  sep = "|")) 
```

Replace `|NA`:

```{r}
distribution_sources %<>% mutate(source = str_replace_all(source, "([|]NA)|(^NA[|])|(NA)", ""))
```

Add source information to `distribution`:

```{r}
distribution %<>% left_join(
  select(distribution_sources, id_sp_region, source),
  by = "id_sp_region")
```

Rename source field:

```{r}
distribution %<>% rename("dwc_source" = "source")
```

## Post-processing

Only keep the Darwin Core columns:

```{r}
distribution %<>% select(starts_with("dwc_"))
```

Drop the `dwc_` prefix:

```{r}
colnames(distribution) <- str_replace(colnames(distribution), "dwc_", "")
```

Preview data:

```{r}
distribution %>% head()
```

Save to CSV:

```{r}
write_csv(distribution, "../data/processed/distribution.csv", na = "")
```

# Description extension

Information for the description extension is contained in the following datasets:

Datasets without regional information:
- habitat

Datasets with regional information:
- pathways
- vector

For each of these datasets, the following steps are required to transform them to the recquired format for the description extension:

1. Remove all empty values
2. Keep distinct vaules only
3. Join the dataset with the literature_reference extension 
4. Map `description`
5. Map `type`
6. Select relevant columns

As these steps are repeated for each of the description datasets, we write a function here:

```{r}
to_description <- function(data_frame, column_name, type){
    data_frame %>% 
    
    # Remove empty values
    filter(
      (!!as.symbol(column_name)) != "") %>% 

    # keep distinct values only
    distinct(idspecies, (!!as.symbol(column_name)), .keep_all = TRUE) %>% 
    
    # Join with reference information
    left_join(
      select(literature_references, sourceid, source),
      by = c("sourceid"))    %>% 
    
    # Map description
    mutate(description = (!!as.symbol(column_name))) %>% 

    # Map `type`:
    mutate(type = type) %>% 
  
    # Keep only `idspecies`, `description`, `type` and `source`:
    select(idspecies, description, type, source)
} 
```

For species with locality information, we need to adapt this function:

```{r}
to_description_with_locality <- function(data_frame, column_name, type){
    data_frame %>% 
    
    # Remove empty values
    filter(
      (!!as.symbol(column_name)) != "") %>% 

    # keep distinct values only
    distinct(idspecies, (!!as.symbol(column_name)), .keep_all = TRUE) %>% 
    
    # Join with reference information
    left_join(
      select(literature_references, sourceid, source),
      by = c("sourceid"))    %>% 
    
    # Join with locality information
    left_join(
      select(sp_in_region_locationID, id_sp_region, locationID),
      by = c("id_sp_region"))    %>% 
    
    # Map description
    mutate(description = paste(locationID, (!!as.symbol(column_name)), sep = " - ")) %>% 

    # Map `type`:
    mutate(type = type) %>% 
  
    # Keep only `idspecies`, `description`, `type` and `source`:
    select(idspecies, description, type, source)
} 
```

### Pathway

```{r}
to_description_with_locality(data_frame = pathways, column_name = "pathway", type = "patwhay")
```


## Vectors

```{r}
to_description_with_locality(vectors, "vector2", "vector")
```


## Habitat information

```{r}
habitat %<>% mutate(eunis_habitat = paste(ideunis, "level", level, "-", habitat))
```

```{r}
to_description(data_frame = habitat, column_name = "eunis_habitat", type = "eunis_habitat")
```

## Native range

```{r}
to_description(data_frame = native_range, column_name = "region", type = "native_range")
```

## Donor area

```{r}
to_description_with_locality(data_frame = donor_area, column_name = "region", type = "donor_area")
```

## Ecofunctional group

ecofucntional_group ecofunct_group

```{r}
to_description(data_frame = ecofunctional_group, 
               column_name = "ecofunct_group",
               type = "ecofunctional_group")
```


## Taxonomic group

taxon_group, taxon_group

```{r}
to_description(data_frame = taxon_group,
               column_name = "taxon_group",
               type = "taxon_group")
```

## Impact on ecology

```{r}
impact %>% group_by(category_ecology) %>% summarize(records = n())
```

Add regional information to `impact`:

```{r}
impact %<>% left_join(
  select(species_localities, id_sp_region, locationID),
  by = "id_sp_region") 
```

Remove empty records:

```{r}
impact_ecology <- impact %<>% filter(category_ecology != "") 
```

Map `description`:

```{r}
impact_ecology %<>% mutate(description = paste(locationID, category_ecology, sep = " - ")) 
```

Map `type`:

```{r}
impact_ecology %<>% mutate(type = "impact_on_ecology")
```

Add source information from distribution_references:

```{r}
impact_ecology %<>% left_join(
  select(filter(
    distribution_references, !is.na(ecoimpact_id)|!is.na(ecological_impact)), 
    id_sp_region, ecoimpact_id, ecological_impact),
  by = "id_sp_region")
```

No duplicates for these references:

```{r}
which(duplicated(impact_ecology$id_sp_region) == TRUE)
```

Map source information:

```{r}
impact_ecology %<>% mutate(source = case_when(
  is.na(ecoimpact_id) & is.na(ecoimpact_id) ~ "",
  !is.na(ecoimpact_id) & is.na(ecological_impact) ~ paste(ecoimpact_id),
  is.na(ecoimpact_id) & !is.na(ecological_impact) ~ paste(ecological_impact),
  !is.na(ecoimpact_id) & !is.na(ecological_impact) ~ paste(ecoimpact_id, ecological_impact, sep ="|")
)) 
```

Keep only `idspecies`, `description`, `type` and `source`:

```{r}
impact_ecology %<>% select(idspecies, description, type, source)
```

## Impact on use

Inspect content:

```{r}
impact %>% group_by(category_uses) %>% summarize(records = n())
```

Remove empty records:

```{r}
impact_use <- impact %<>% filter(category_uses != "") 
```

Map description:

```{r}
impact_use %<>% mutate(description = paste(locationID, category_uses, sep = " - ")) 
```

Map type:

```{r}
impact_use %<>% mutate(type = "impact_on_uses")
```

Add source information from distribution_references:

```{r}
impact_use %<>% left_join(
  select(filter(
    distribution_references, !is.na(useimpact_id)|!is.na(impact_on_uses)), 
    id_sp_region, useimpact_id, impact_on_uses),
  by = "id_sp_region")
```

No duplicates for these references:

```{r}
which(duplicated(impact_use$id_sp_region) == TRUE)
```

Map source information:

```{r}
impact_use %<>% mutate(source = case_when(
  is.na(useimpact_id) & is.na(impact_on_uses) ~ "",
  !is.na(useimpact_id) & is.na(impact_on_uses) ~ paste(useimpact_id),
  is.na(useimpact_id) & !is.na(impact_on_uses) ~ paste(impact_on_uses),
  !is.na(useimpact_id) & !is.na(impact_on_uses) ~ paste(useimpact_id, impact_on_uses, sep ="|")
)) 
```

Keep only `idspecies`, `description`, `type` and `source`:

```{r}
impact_use %<>% select(idspecies, description, type, source)
```

## degree of establishment

```{r}
degree_of_establishment %>% group_by(population_status) %>% summarize(records = n())
```

Remove empty records:

```{r}
degree_of_establishment %<>% filter(population_status != "") 
```

Add regional information to `degree_of_establishment`:

```{r}
degree_of_establishment %<>% left_join(
  select(species_localities, id_sp_region, locationID),
  by = "id_sp_region") 
```

Map `description`:

```{r}
degree_of_establishment %<>% mutate(description = paste(locationID, population_status, sep = " - ")) 
```

Map `type`:

```{r}
degree_of_establishment %<>% mutate(type = "degree_of_establishment")
```

Add source information from distribution_references:

```{r}
degree_of_establishment %<>% left_join(
  select(filter(
    distribution_references, !is.na(status)), 
    id_sp_region, status),
  by = "id_sp_region")
```

No duplicates for these references:

```{r}
which(duplicated(degree_of_establishment$id_sp_region) == TRUE)
```

Map source information:

```{r}
degree_of_establishment %<>% mutate(source = case_when(
  is.na(status) ~ "",
  !is.na(status) ~ paste(status))) 
```

Keep only `idspecies`, `description`, `type` and `source`:

```{r}
degree_of_establishment %<>% select(idspecies, description, type, source)
```

## current distribution

```{r}
current_distribution %>% group_by(current_distribution) %>% summarize(records = n())
```

Remove empty records:

```{r}
current_distribution %<>% filter(current_distribution != "") 
```

Add regional information to `current_distribution`:

```{r}
current_distribution %<>% left_join(
  select(species_localities, id_sp_region, locationID),
  by = "id_sp_region") 
```

Map `description`:

```{r}
current_distribution %<>% mutate(description = paste(locationID, current_distribution, sep = " - ")) 
```

Map `type`:

```{r}
current_distribution %<>% mutate(type = "current_distribution")
```

Add source information from distribution_references:

```{r}
current_distribution %<>% left_join(
  select(filter(
    distribution_references, !is.na(current_distrib) | !is.na(current_distribution)), 
    id_sp_region, current_distrib, current_distribution),
  by = "id_sp_region")
```

No duplicates for these references:

```{r}
which(duplicated(current_distribution$id_sp_region) == TRUE)
```

Map source information:

```{r}
current_distribution %<>% mutate(source = case_when(
  is.na(current_distrib) & is.na(current_distribution.y) ~ "",
  !is.na(current_distrib) & is.na(current_distribution.y) ~ paste(current_distrib),
  is.na(current_distrib) & !is.na(current_distribution.y) ~ paste(current_distribution.y),
  !is.na(current_distrib) & !is.na(current_distribution.y) ~ paste(current_distrib, current_distribution.y, sep = "|"))) 
```

Keep only `idspecies`, `description`, `type` and `source`:

```{r}
current_distribution %<>% select(idspecies, description, type, source)
```

## Region of first observation

```{r}
region_first_record %>% group_by(region_of_first_record) %>% summarize(records = n())
```

Remove empty records:

```{r}
region_first_record %<>% filter(region_of_first_record != "") 
```

Add regional information to `region_first_record`:

```{r}
region_first_record %<>% left_join(
  select(species_localities, id_sp_region, locationID),
  by = "id_sp_region") 
```

Map `description`:

```{r}
region_first_record %<>% mutate(description = paste(locationID, region_of_first_record, sep = " - ")) 
```

Map `type`:

```{r}
region_first_record %<>% mutate(type = "region_of_first_record")
```

Add source information from distribution_references:

```{r}
region_first_record %<>% left_join(
  select(filter(
    distribution_references, !is.na(first_observation)), 
    id_sp_region, first_observation),
  by = "id_sp_region")
```

No duplicates for these references:

```{r}
which(duplicated(region_first_record$id_sp_region) == TRUE)
```

Map source information:

```{r}
region_first_record %<>% mutate(source = case_when(
  is.na(first_observation) ~ "",
  !is.na(first_observation) ~ paste(first_observation))) 
```

Keep only `idspecies`, `description`, `type` and `source`:

```{r}
region_first_record %<>% select(idspecies, description, type, source)
```

## Union information:

```{r start_description_ext}
description <- bind_rows(
  pathways, 
  vectors, 
  habitat, 
  native_range, 
  donor_area, 
  ecofunctional_group, 
  taxon_group, 
  impact_ecology, 
  impact_use, 
  degree_of_establishment,
  current_distribution,
  region_first_record)
```

Map to DwC terms:

### taxonID

```{r}
description %<>% mutate(dwc_taxonID = idspecies)
```

### description

```{r}
description %<>% mutate(dwc_description = description)
```

### type

```{r}
description %<>% mutate(dwc_type = type) 
```

### source

```{r}
description %<>% mutate(dwc_source = source) 
```

## Post-processing

1. Only keep the Darwin Core columns.
  
```{r}
description %<>% select(starts_with("dwc_"))
```
  
2. Drop the `dwc_` prefix.
  
```{r}
colnames(description) <- str_replace(colnames(description), "dwc_", "")
```

3. Sort on `taxonID`.

```{r}
description %<>% arrange(taxonID)
```

4. Preview data:

```{r}
description %>% head()
```

5. Save to [CSV]().

```{r}
write_csv(description, "../data/processed/description.csv", na = "")
```



